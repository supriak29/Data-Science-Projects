{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32883804",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e48fe5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8ac436",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up seeds before I do any kind of model just so that I can replicate all the results that I've done before.\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f287bcf0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3e644f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Financial-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f8f22a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns= ['months_employed']) # getting rid of the column that we found to be kind of faulty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469427b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a84715",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset['personal_account_months'] = (dataset.personal_account_m + (dataset.personal_account_y * 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cf8580",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal_account_m</th>\n",
       "      <th>personal_account_y</th>\n",
       "      <th>personal_account_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personal_account_m  personal_account_y  personal_account_months\n",
       "0                   6                   2                       30\n",
       "1                   2                   7                       86\n",
       "2                   7                   1                       19\n",
       "3                   2                   7                       86\n",
       "4                   2                   8                       98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[ ['personal_account_m', 'personal_account_y', 'personal_account_months'] ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b621a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns= ['personal_account_m', 'personal_account_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cbc5b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23299238",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To do so, we have to leverage the Pandas function PD dot Getdummies.\n",
    "<br><br>\n",
    "It's going to find all the categorical variables, all the variables that are not numeric and it's going to encode them into their own dummy variables and it's going to do it all for us very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a0dbc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8078c257",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset) # first we run dataset and we set it to the result of pandas that getdummies on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4a1138",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Entry_id', 'age', 'home_owner', 'income', 'years_employed',\n",
       "       'current_address_year', 'has_debt', 'amount_requested', 'risk_score',\n",
       "       'risk_score_2', 'risk_score_3', 'risk_score_4', 'risk_score_5',\n",
       "       'ext_quality_score', 'ext_quality_score_2', 'inquiries_last_month',\n",
       "       'e_signed', 'personal_account_months', 'pay_schedule_bi-weekly',\n",
       "       'pay_schedule_monthly', 'pay_schedule_semi-monthly',\n",
       "       'pay_schedule_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bd8c4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ec40f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "- The pay schedule columns are the biweekly label, the monthly label, the semi monthly label and the weekly label.\n",
    "    - So it is split that column into four different ones.\n",
    "<br><br>\n",
    "- we need to remove one of these columns from the data set to avoid the dummy variable trap, \n",
    "    - meaning that if we keep all of these columns here, they're going to be now dependent column, not linearly independent columns, which is what we want.\n",
    "<br>\n",
    "    - So by removing one of them, we make them linearly independent again.\n",
    "<br><br>\n",
    "- So which one are we going to remove? (your choice)\n",
    "    - I personally going to remove semi-monthly just because semi-monthly is the weirdest of the pay schedules.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b441ad",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b8f5797",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns= ['pay_schedule_semi-monthly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db2d995",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get rid of all the columns that are useful but are not going to be part of the training set\n",
    "# removing extra columns\n",
    "response = dataset['e_signed']\n",
    "users = dataset['Entry_id']\n",
    "dataset = dataset.drop(columns= ['e_signed', 'Entry_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1ff1b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Splitting into Train and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da3511",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train test split function is going to return four items.\n",
    "<br>\n",
    "The x axis of the independent variables for the train and test as well as \n",
    "<br>\n",
    "The dependent variables for the train and the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982bed8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, # X value\n",
    "                                                    response, # y value\n",
    "                                                    test_size=0.2, # 20% is the size of response variable\n",
    "                                                    random_state=0\n",
    "                                                   )\n",
    "# We have a train test split immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fe08d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631740d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler() # we first create the standard scalar by calling the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa5dce3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, this resulting data set is not going to be a Pandas dataframe anymore, meaning that it is going to lose the column names and it's going to lose the indexes.\n",
    "<br>\n",
    "So we want to convert this to an actual Pandas dataframe too. So we're going to apply pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f64d5c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit the scalar to the X train set and then we're going to transform the X train based on that scaling\n",
    "# This is the result of the X train being scaled.\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e34127fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we're going to actually do the same thing - test set\n",
    "# only transform because we already have fitted the scaler\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd454cb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now, what is next to do is to copy the columns in the indexes to this Xtrain and xtest two datasets \n",
    "# because those have been lost\n",
    "# That should work to copy the original columns to the xtrain\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a03de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So now our X train and everything has been scaled properly and the indexes and the columns have been recovered.<br>\n",
    "So the only thing left to do is to actually set the X_train to this new X_train2 value.<br>\n",
    "So this is just making sure that we keep the name of the X train consistent in the future lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57148a84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48a0cc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7762a3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<u><i><b>Comparing Models:</b></i></u>\n",
    "<br>\n",
    "And we're going to apply different models to our dataset and compare the results that we get out of each one.<br>\n",
    "At the end, we're going to select one best model and we're going to move forward with that one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c183295",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "322cbda4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# L1 penalty: the lasso penalty \n",
    "# ---> this is going to make sure that our data is penalized if one particular variable has too much of a coefficient.\n",
    "\n",
    "# this may not be needed, but if we add this to this model right now, \n",
    "# we're going to make sure that we're comparing the very best options of each of the different methods that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcba6da6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predicting test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4501d131",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea43193",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c91827b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression (Lasso)  0.562535   0.576386  0.706432  0.634817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put results in pandas dataframe\n",
    "# So the first argument should be the name of the model: Linear Regression\n",
    "# we're going to add here in parentheses is lasso, because this is a lasso penalty\n",
    "# Then name the columns\n",
    "results = pd.DataFrame([['Logistic Regression (Lasso)', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bf6f5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>\n",
    "- Precision: \n",
    "    - The precision is the rate of true positives divided by the rate of true positives and false positives.\n",
    "    - What does that mean?\n",
    "<br>\n",
    "-- That means that out of all the predicted positives, we want to know how many have been predicted right and how many have been predicted wrong.\n",
    "<br><br>\n",
    "- Recall score:\n",
    "    - what it means is true positives divided by true positives and false negatives\n",
    "    - So the recall is telling us that out of all the actual positives, we have predicted them to be true around 70% of the time\n",
    "    - recall is 70% ----> Now that means that there's some bias in this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2454796",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model 2: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211eea36",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Linear Kernal\n",
    "<br>\n",
    "SVM(Linear)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df4ea24",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # importing Support Vector Classifier\n",
    "\n",
    "classifier = SVC(random_state=0, kernel='linear')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b48cbb81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predicting test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "493d5c96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da6aa7a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5410bd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568118</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  SVM (Linear)  0.568118   0.577597  0.735477  0.647045"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34c794ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568118</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1                 SVM (Linear)  0.568118   0.577597  0.735477  0.647045"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results._append(model_results, ignore_index=True) # append this to the initial results table\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad854e1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# results =  results.drop([1, 2, 3, 4], axis='index') ---- drop rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee2ad2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- accuracy, precision: \n",
    "    - Almost identical.\n",
    "\n",
    "- Recall: \n",
    "    - Pretty high\n",
    "    - It's even higher than the one previously\n",
    "    - So obviously there's still bias in this linear support vector machine model\n",
    "\n",
    "- F1 score is 64:\n",
    "    - A little bit higher, but not that much better\n",
    "---------\n",
    "<br>\n",
    "So now let's do the same for a different kernel.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613ff92",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### SVM: RBF Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6930633",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # importing Support Vector Classifier\n",
    "\n",
    "classifier = SVC(random_state=0, kernel='rbf')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fcd82ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10b7d567",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score \n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f3d61d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568118</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.591569</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.645505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1                 SVM (Linear)  0.568118   0.577597  0.735477  0.647045\n",
       "2                    SVM (RBF)  0.591569   0.605730  0.690871  0.645505"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results._append(model_results, ignore_index=True) # append this to the initial results table\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72eeb6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>RDF actually gives us a better accuracy by almost three points of a percent.\n",
    "The precision increases as well and the recall goes down a little bit.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4997c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Model 3: Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94aaca79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "classifier = RandomForestClassifier(random_state=0, n_estimators=100, criterion='entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4074c71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score \n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a2c4083",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Lasso)</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.706432</td>\n",
       "      <td>0.634817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.568118</td>\n",
       "      <td>0.577597</td>\n",
       "      <td>0.735477</td>\n",
       "      <td>0.647045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.591569</td>\n",
       "      <td>0.605730</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.645505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (n=100)</td>\n",
       "      <td>0.621720</td>\n",
       "      <td>0.640098</td>\n",
       "      <td>0.678942</td>\n",
       "      <td>0.658948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression (Lasso)  0.562535   0.576386  0.706432  0.634817\n",
       "1                 SVM (Linear)  0.568118   0.577597  0.735477  0.647045\n",
       "2                    SVM (RBF)  0.591569   0.605730  0.690871  0.645505\n",
       "3        Random Forest (n=100)  0.621720   0.640098  0.678942  0.658948"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model with n=100 trees\n",
    "model_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results._append(model_results, ignore_index=True) # append this to the initial results table\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c61f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>\n",
    "random forest with 100 trees has given us a 62%, which is almost almost exactly, actually 3% higher than the SVM, which was the highest accuracy we had\n",
    "<br><br>\n",
    "precision has gone up and the recall has gone down by two points, meaning that it is more balanced\n",
    "<br><br>\n",
    "So now that we have decided which model to use, the last step that we're going to care about is to actually validate this model, to see if it performs like it says it does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc70eb0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d5f7a4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.63 (+/-0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator=classifier, # classifer which we built - random forest classifier with 100 trees\n",
    "                            X = X_train,\n",
    "                            y = y_train,\n",
    "                            cv = 10) # number of folds = 10 \n",
    "\n",
    "print(\"Random Forest Classifier Accuracy: %0.2f (+/-%0.2f)\" %(accuracies.mean(), accuracies.std() *2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2c148",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the accuracy that we got for K-fold, cross validation was 63% with \n",
    "standard deviation of around three points, meaning that it could be from 60 to 66\n",
    "<br><br>\n",
    "This is even higher than the run we did in the results dataset.\n",
    "<br><br>\n",
    "So then we can finally guarantee that random forest is the best option.<br>\n",
    "We have to run here and we're going to be using it going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84978d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Parameter Tuning - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3cf74",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to fine tune this model.<br>\n",
    "We're going to do parameter tuning.<br>\n",
    "And what this is going to accomplish is it's going to find the best parameters to random forest that \n",
    "gives us the most accuracy in our model.\n",
    "<br><br>\n",
    "So if we select a range of options to choose for each of those parameters and we try every single combination\n",
    "of those to see which one performs the best with our data, that is pretty much what Gridsearch is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8a87f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Round 1: Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14e156bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we're going to give it parameters which is going to be a dictionary of column names and possible values\n",
    "parameters = {\"max_depth\":[3, None],\n",
    "             \"max_features\":[1, 5, 10],\n",
    "             \"min_samples_split\":[2, 5, 10],  \n",
    "             \"min_samples_leaf\":[1, 5, 10],\n",
    "             \"bootstrap\":[True, False],\n",
    "             \"criterion\":[\"entropy\"]}\n",
    "# The reason we do two, five and ten instead of one, five and ten as above is because for min samples split, the default is two.\n",
    "# Bootstrap: There's only two possible values for this argument - True / False\n",
    "# The criterion is just going to ensure that we're trying this with entropy and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7707f092",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,   # model = random forest;\n",
    "                          param_grid=parameters,\n",
    "                          scoring=\"accuracy\",      # So we want to judge which model is best simply based on its accuracy\n",
    "                          cv=10,                   # k-fold cross validation\n",
    "                          n_jobs=1 # n_jobs=-1               # I want it to use all of my cores to run this bunch of models\n",
    "                          )  \n",
    "# n_jobs: \n",
    "#   If you don't want it to take a big strain on your computer, \n",
    "#   you can change this to just one to just leave it as is as a default.\n",
    "#   And that way it doesn't take too much of a toll on your computer when you're running it.\n",
    "#   But I wanted to finish this as soon as possible, so I'm going to use negative one, which is again,\n",
    "#   means just that you're using every single core available on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd978f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit this model\n",
    "\n",
    "t0 = time.time() # we use the time library because we want to time how long all of this takes\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()  # set the final time\n",
    "\n",
    "print(\"Took %0.2f seconds\" %(t1-t0)) # float of 2 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05b945",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if some weird error shows up: \n",
    "#                               - pip install joblib\n",
    "#                               - conda install joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71285e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Round 2: Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bfc8e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "we're going to base our new results on the previous results\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37615f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\":[None],             # prev: none is the most optimal max depth\n",
    "             \"max_features\":[3, 5, 7],        # prev: 5; so we try 3 and 7 on the edges to cover more range \n",
    "             \"min_samples_split\":[8, 10, 12], # prev: 10\n",
    "             \"min_samples_leaf\":[1, 2, 3],    # prev: 1\n",
    "             \"bootstrap\":[True],       # prev: True\n",
    "             \"criterion\":[\"entropy\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a53f5b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,  \n",
    "                          param_grid=parameters,\n",
    "                          scoring=\"accuracy\",      \n",
    "                          cv=10,                   \n",
    "                          n_jobs=1                \n",
    "                          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87222148",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" %(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53f3f1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>The results are the exact same that we got on the first round.<br>\n",
    "This tells us that the results we got on the first round are just the optimal of all the ones we have tried.\n",
    "<br><br>\n",
    "So we're going to stick to that and run our tests on that particular set of results.\n",
    "<br><br>\n",
    "Now, the final part here is to apply our model to our test set so that we can see if this set of results actually improves the accuracy or not.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab095638",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Predicting Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251117c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score \n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest (n=100), GSx2 + Entropy', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results._append(model_results, ignore_index=True) # append this to the initial results table\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3aa62",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Round 1: Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a7758",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So this grid search model is actually performing better than the original random forest model.<br>\n",
    "The second round didn't give us any lift, but the first one did.\n",
    "<br><br>\n",
    "Now, we attempted this grid search on the entropy version of Random Forest.<br>\n",
    "We can do the exact same, but using the gini version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f9cb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\":[3, None],\n",
    "             \"max_features\":[1, 5, 10],\n",
    "             \"min_samples_split\":[2, 5, 10],  \n",
    "             \"min_samples_leaf\":[1, 5, 10],\n",
    "             \"bootstrap\":[True, False],\n",
    "             \"criterion\":[\"gini\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b322d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,   \n",
    "                          param_grid=parameters,\n",
    "                          scoring=\"accuracy\",      \n",
    "                          cv=10,                   \n",
    "                          n_jobs=1 # n_jobs=-1               \n",
    "                          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200d25d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time() \n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()  \n",
    "\n",
    "print(\"Took %0.2f seconds\" %(t1-t0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e405fab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb4ed9cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Round 2: Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9791df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\":[None],            # None \n",
    "             \"max_features\":[8, 10, 12],     # 10\n",
    "             \"min_samples_split\":[2, 3, 4],  # 2\n",
    "             \"min_samples_leaf\":[8, 10, 12], # 10\n",
    "             \"bootstrap\":[True],      \n",
    "             \"criterion\":[\"gini\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a6dc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,  \n",
    "                          param_grid=parameters,\n",
    "                          scoring=\"accuracy\",      \n",
    "                          cv=10,                   \n",
    "                          n_jobs=1                \n",
    "                          )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf64eb7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" %(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c34bbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score \n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest (n=100), GSx2 + Gini', acc, prec, rec, f1]], \n",
    "                       columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "results = results._append(model_results, ignore_index=True) # append this to the initial results table\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e238b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- So we see the Randomforest with Gridsearch applied two times on Guinea gave us a accuracy of 63.5 on that test set, a precision of 64.9, a recall of 70% and a F1 score of 63.6 7.3.\n",
    "<br><br>\n",
    "- So random forest with Entropy and Guinea are not that different.\n",
    "- We can assume that the difference here are just due to randomness, but overall we're going to just stick to random forest entropy and realize that this is the best model that we can possibly use\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334fcd6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>\n",
    "The difference between Guinea and entropy has to do a lot with what this criterion means. <br>\n",
    "So this criterion is the splitting criterion. <br>\n",
    "So that means that when a parent is partitioned into two child regions in the tree and the decision tree that this random forest is made out of.\n",
    "<br>\n",
    "We need a particular splitting criterion for this.\n",
    "<br><br>ENTROPY:<br>\n",
    "And the entropy is a criterion and there is a whole equation behind this that is meant to maximize the informational content that our random forest has.\n",
    "<br>\n",
    "So the equation makes it so that we're maximizing the information that we keep after every split.\n",
    "<br><br>GINI:<br>\n",
    "The Gini version, on the other hand, minimizes the probability of mislabeling.\n",
    "<br>\n",
    "So when it does the splitting, it does so in a way that it values not mislabeling our leaves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205adba5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f2701",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Combining the predictions that we had with their actual values and the user identifiers, pretty much mapping every user to whatever prediction we did for that user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e4265",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b> Formatting Final Results <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3df63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concatenate the Y test, which is a column of E sign, and our user identifier, which is our entry IDs.\n",
    "final_results = pd.concat([y_test, users], axis=1).dropna() # it makes each of these a column\n",
    "\n",
    "final_results['predictions'] = y_pred\n",
    "\n",
    "final_results = final_results[['Entry_id', 'e_signed', 'predictions']] # reorder this results in a way that makes more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf0a82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We already know that the accuracy for this is on the level of 63%, so that's pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba716ef",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ba9b1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Predicting the likelihood of you signing a loan based on financial history.\n",
    "<br>\n",
    "- Now, our model, of course, has given us the 64% accuracy. \n",
    "- With it, we have an algorithm that can help predict whether or not a user will complete this signing step.\n",
    "<br>\n",
    "- One way to leverage this model is to target those predicted not to reach the sign phase with customized onboarding.\n",
    "    - This means that when a lead arrives from a marketplace, they may receive a different onboarding experience based on how likely they are to finish the general onboarding process, the original process.\n",
    "    - This can help our company minimize how many people drop off from the onboarding funnel.\n",
    "        - This funnel of screens is effective as we as a company decide to build it.\n",
    "        - Therefore, any user drop off in this funnel falls entirely on our shoulders.\n",
    "<br>\n",
    "- This is entirely about how we design this onboarding so we can maximize how many people can reach that screen.\n",
    "    - So with new onboarding screens built intentionally to lead these users to finalize the loan application, we can actually attempt to get more than 40% of those users predicted not to finish the process to actually complete the E sign step.\n",
    "\n",
    "- And why 40%?\n",
    "    - Well, we know that our model has around a 64% accuracy.\n",
    "    - So if of all the people who have been predicted not to reach the E sign step, 64% of them have been correctly predicted on average.\n",
    "    - Of course, this means that only around 36 to 40% of this subset of people are expected to reach the e sign step in to complete it.\n",
    "\n",
    "- So if we can change the onboarding process so we can get more than this 36 to 40% number and we can increase it, then we can drastically increase profits.\n",
    "<br>\n",
    "- Many lending companies, like the ones we are pretending to work for, provide hundreds if not thousands of loans every day, and they gain money for each one of these loans.\n",
    "<br>\n",
    "- So if we can increase the percentage of loan takers and we multiply this percentage by all the thousands or hundreds of people that were giving loans every day, we are increasing profits drastically.\n",
    "- And all of this is done with a simple model.\n",
    "<br>\n",
    "- Studies course is that we don't need complex machine learning models to get value into your company.\n",
    "- Many times when data scientists are joining a company, they're going to join with very small set of experience.\n",
    "- Not everybody is going to have 5 to 10 years of experience, so they're only going to know how to build simple models.\n",
    "- But as long as they understand the business context and they know how to leverage this model, then the profits are there for you to acquire.\n",
    "<br>\n",
    "- So never fret if your model can be a little bit simple as long as the results are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3fd7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
